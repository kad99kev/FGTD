# Text2Face ðŸ“ -> ðŸ‘§ðŸ‘±

## ðŸ¤ž Motivation

Powerful Generative Adverserial Networks have been used in the past to automatically synthesize realistic images from text. However, these existing task have been used for simple tasks such as flowers and birds.
So, our aim is to focus on a less addressed domain of face generation from fine-granined textual description of faces.

However, as we are still undergrad students, we decided to not only build our main GAN, but also a ladder of GANs that helped strengthen our understanding, in hopes to inspire others.

## ðŸ“ˆ Our Progress Ladder 

**Step 1. We started with Simple GANs on the MNIST digit dataset** ðŸ”¢

ðŸ”— [Code, References and Output]

**Step 2. Progressed our way up to understanding other GAN architectures on the digit and fashion MNIST datasets.** ðŸ‘— ðŸ‘•

ðŸ”— [Conditional GANS Code, References and Output]

ðŸ”— [Auxillary Conditional GANS Code, References and Output]

ðŸ”— [Deep Convolution GANS Code, References and Output]

**Step 3. Researched about past implementations on the topic**
(Some of the research paper links)

* [FTGAN : A fully Generative Adverserial Network for Text to Face Generation](https://arxiv.org/pdf/1904.05729.pdf)
* [Text2FaceGAN : Face Generation from Fine Grained Description](https://arxiv.org/pdf/1911.11378.pdf) 
* [Generative Adverserial Text to Image Synthesis](https://arxiv.org/pdf/1605.05396.pdf)




